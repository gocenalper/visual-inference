# ğŸš€ Visual Inference - Deepfake Detection

![Python](https://img.shields.io/badge/Python-3.10-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0-red.svg)
![Docker](https://img.shields.io/badge/Docker-Supported-brightgreen.svg)

ğŸ” **Visual Inference** is a deepfake detection system that utilizes **Xception-based feature extraction** and **Transformer-based sequence modeling** to classify **real vs. fake images**. This project provides a **Dockerized solution** to simplify model deployment and inference.

---

## ğŸ“Œ Features

âœ”ï¸ **Xception-based** feature extraction for frame analysis  
âœ”ï¸ **Transformer Encoder** for sequence modeling  
âœ”ï¸ **Cross-Attention Mechanism** to refine embeddings  
âœ”ï¸ **Docker support** for easy deployment  
âœ”ï¸ **Inference statistics** to analyze model performance  

---

## ğŸ”§ Installation & Setup

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone git@github.com:gocenalper/visual-inference.git
cd visual-inference
```

### **2ï¸âƒ£ Install Dependencies (For Local Usage)**
```bash
pip install torch torchvision timm tqdm pillow
```

---

## ğŸ³ Running with Docker

We provide a **lightweight Docker image** for running the model without manually installing dependencies.

### **1ï¸âƒ£ Build the Docker Image**
```bash
docker build -t dfdc-inference .
```

### **2ï¸âƒ£ Run the Docker Container (Mounting Dataset & Code)**
Run the following command to **mount your dataset and code inside the container**:
```bash
docker run --rm -it -v "$(pwd)":/app dfdc-inference
```

### **3ï¸âƒ£ Run with GPU Support (Optional)**
If your machine has **CUDA-enabled GPUs**, use:
```bash
docker run --gpus all --rm -it -v "$(pwd)":/app dfdc-inference
```

---

## ğŸ–¼ Dataset Structure

The dataset should be **mounted** in the following format:

```
/DFDC/
    â”œâ”€â”€ REAL/
    â”‚   â”œâ”€â”€ TRAIN/
    â”‚   â”‚   â”œâ”€â”€ video_0001/
    â”‚   â”‚   â”‚   â”œâ”€â”€ frame_01.jpg
    â”‚   â”‚   â”‚   â”œâ”€â”€ frame_02.jpg
    â”‚   â”‚   â”œâ”€â”€ video_0002/
    â”‚   â”œâ”€â”€ TEST/
    â”‚   â”œâ”€â”€ VAL/
    â”œâ”€â”€ FAKE/
    â”‚   â”œâ”€â”€ TRAIN/
    â”‚   â”‚   â”œâ”€â”€ video_0003/
    â”‚   â”‚   â”‚   â”œâ”€â”€ frame_01.jpg
    â”‚   â”‚   â”‚   â”œâ”€â”€ frame_02.jpg
    â”‚   â”œâ”€â”€ TEST/
    â”‚   â”œâ”€â”€ VAL/
```

---

## ğŸš€ Running Inference

Once the **Docker container is running**, the model will process **test images** and print real-time statistics:

```
ğŸ” Running Untrained Model Inference on Test Data...

ğŸ“Œ Image 1: Predicted = FAKE, Actual = REAL, âŒ Incorrect
ğŸ“Œ Image 2: Predicted = REAL, Actual = FAKE, âŒ Incorrect
ğŸ“Œ Image 3: Predicted = REAL, Actual = REAL, âœ… Correct
ğŸ“Œ Image 4: Predicted = FAKE, Actual = FAKE, âœ… Correct

ğŸ“Š **Inference Statistics (Before Training)**
ğŸ”¹ Total Images Processed: 1000
ğŸŸ¢ Real Predictions: 500 (50.0%)
ğŸ”´ Fake Predictions: 500 (50.0%)
âœ… Correct Predictions: 495 (49.5%) Accuracy
```

---

## ğŸ›  Troubleshooting

### **1ï¸âƒ£ Docker Build Fails: "No space left on device"**
Run
